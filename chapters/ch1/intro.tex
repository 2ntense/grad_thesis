Recent trends in artificial intelligence (AI) development indicate a substantial surge in the complexity and size of AI models since the advent of the deep learning era \autocite{EpochDatabaseVisualization}.
Sophisticated state-of-the-art AI models, such as those used in natural language processing and computer vision, can vary widely in complexity, with some containing as few as thousands of parameters and others exceeding a trillion.
These parameters are the fundamental components that AI models manipulate to learn from data and make predictions or decisions.
Processing such huge models requires an extensive amount of computational power.
These models require the processing power of high-performance computing systems, including powerful GPUs and large memory pools, for both training and inference tasks
However, the deployment of AI solutions is not limited to these high-resource environments.
There is a significant push to bring AI capabilities closer to the end-users, which is where edge computing comes into play.
The shift towards edge AI is driven by a need for speed, efficiency, and privacy. 
To make decisions and take actions instantaneously, processing needs to happen locally on the device.
This also reduces power consumption, a crucial factor for extending battery life and making AI applications more sustainable. 
Furthermore, processing data on-device enhances privacy by keeping sensitive information within the user's control.
