\section{Problem statement}
\label{section:ch8/problem_statement}

With the following given:
\begin{itemize}
    \item A large model with $N$ layers represented as a set $L = \left\{ \, l_1, l_2, \ldots, l_N \, \right\}$.
    \item The \graicore{} with a maximum memory capacity of $M$.
    \item A compiler/mapper that can be configured with parameters $\pi_i$ for each partition $p_i$.
    \item Target total inference latency $T$.
\end{itemize}
We determine an optimal partitioning strategy that divides the model into $K$ consecutive sets of layers ($P = \{p_1, p_2 \ldots, p_K\}$), where each $p_i \subseteq L$, and find the optimal compiler parameters $\pi_i$ for each partition.
This partitioning and parameter selection must minimize energy consumption, when executing the partitioned model on the \graicore{}, while satisfying the following constraints:

\begin{description}
    \item[Latency:] 
    % the total inference time must not exceed $T$.
    The total inference time consists of the processing time and configuration time of every partition in $P$.
    The total inference time must not exceed $T$.
    The value for $T$ is variable and depends on the specific model in question and the requirements from the end-user.
    \begin{equation}
        \lattotal(p_i, \pi_i) = \sum_{i=1}^{K} \left( \latconf(p_i, \pi_i) + \latproc(p_i, \pi_i) \right) \leq T
    \end{equation}
    \item[Containability:]
    the data size of the partition mapped with some compiler parameters must not exceed the \graicore{}'s total memory capacity $M$.
    The data size of a mapped partition is influenced by the layers contained in the partition and the used compiler parameters.
    \begin{equation}
        \forall i \in \{i \in \mathbb{N} \mid 1 \leq i \leq K\}, \; \writeamount(p_i, \pi_i) \leq M
    \end{equation}
    \item[Mappability:]
    the partition in combination with some compiler parameters must be mappable with the compiler.
    \begin{equation}
        \forall i \in \{i \in \mathbb{N} \mid 1 \leq i \leq K\}, \; \mappable(p_i, \pi_i)
    \end{equation}
    \item[Exclusiveness:]
    to ensure that the partitioned model maintains the accuracy of the original large model, every layer must belong to exactly one partition.
    \begin{equation}
        \bigcap_{p \in P} p = \emptyset \wedge \bigcup_{p \in P}p = L
    \end{equation}
    \item[Consecutiveness:]
    each partition is a consecutive subset of layers.
    \begin{equation}
        \forall p \in P, \; p \subseteq \{l_i \in L \mid \alpha \leq i \leq \beta\} \; \text{for} \;  \alpha, \beta, i \in \mathbb{N} \wedge 1 \leq \alpha \leq \beta
    \end{equation}
    \item[Sequentiality:]
    to ensure the execution of the partitions happens in a strict sequential manner, we define a relation $\triangleright$ on the set $P$ such that $p_i \triangleright p_j$ if and only if $p_i$ must be executed before $p_j$.
    This relation adheres to the following axiom:
    \begin{equation}
        \forall i \in \{i \in \mathbb{N} \mid 1 \leq i < K \}, \; p_i \triangleright p_{i+1}
    \end{equation}
    This axiom describes that partitions are strictly executed in order of their index. It also implies that:
    \begin{itemize}
        \item No skipping is possible. A partition cannot be executed before another partition that is more than one step ahead. For example, $p_1 \triangleright p_3$.
        \item Execution of the same partition in sequence is not allowed (e.g., $p_1 \triangleright p_1$).
    \end{itemize}

\end{description}
